##account
  #service account - there is a service account resource maqnaged by k8s api. 
  #normal user: there is no k8s user resource
    it is assument that a cluster independent serivice managed normal users who hold the certificate 
    #service account- are namespaces- sa "default" every namespace used by the Pods  - it can be used to talk to k8s api. 
    #there will be secret used by the token 
  #hand on session 
    #we will create a service account and use in pod 
    use service account token to connect to the api from inside a pod
#this will show the default sa
root@k8s-master-node:~# kubectl get sa
NAME      SECRETS   AGE
default   0         15d
    #we will create a new sa account called as accessor
root@k8s-master-node:~# kubectl create sa accessor
serviceaccount/accessor created
root@k8s-master-node:~# kubectl get sa
NAME       SECRETS   AGE
accessor   0         10s
default    0         15d
root@k8s-master-node:~# 
  #lets get the token of this service account
  root@k8s-master-node:~# kubectl create token accessor
    #this token are not permananet once you get the token you can paste the same to jwt inspector 
    https://jwt.io/
#paste the token in side site
  #in the site you can see that the token is for system service accessor
    },
  "nbf": 1743578765,
  "sub": "system:serviceaccount:default:accessor"
}
##################
  we need to check that pod has access to the service account toekn 
  #we will create a pod 
  root@k8s-master-node:~# kubectl run accessor --image=nginx -o yaml --dry-run=client
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: accessor
  name: accessor
spec:
  containers:
  - image: nginx
    name: accessor
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
root@k8s-master-node:~# kubectl run accessor --image=nginx -o yaml --dry-run=client > pod.yml
root@k8s-master-node:~# 

###once created open the pod in the vi editor
  vi pod.yml
  #############
  apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: accessor
  name: accessor
spec:
  serviceAccount: test #this sa do not exist and lets try to create the pod 
  containers:
  - image: nginx
    name: accessor
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
##lets try to create the pod you will get forbiden error
  root@k8s-master-node:~# kubectl apply -f pod.yml 
Error from server (Forbidden): error when creating "pod.yml": pods "accessor" is forbidden: error looking up service account default/test: serviceaccount "test" not found
root@k8s-master-node:~# 
##lets change the sa which exist if no sa in define it will take the default one
  vi pod.yml
  apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: accessor
  name: accessor
spec:
  serviceAccount: accessor #change the sa which we have created earlier and apply the manifest file
  containers:
  - image: nginx
    name: accessor
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
########################
  pod is running and now we will go inside the pod
  ###########
  root@k8s-master-node:~# kubectl -f pod.yml create
pod/accessor created

NAME       READY   STATUS    RESTARTS      AGE
accessor   1/1     Running   0             13s
#############we need to check where is the service account is mapped
    root@k8s-master-node:~# kubectl exec -it accessor -it -- bash
root@accessor:/# mount | grep ser
overlay on / type overlay (rw,relatime,lowerdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/249/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/248/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/247/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/246/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/245/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/244/fs:/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/243/fs,upperdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/250/fs,workdir=/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/250/work,uuid=on,nouserxattr)
tmpfs on /run/secrets/kubernetes.io/serviceaccount type tmpfs (ro,relatime,size=3904812k,inode64)
root@accessor:/# 
  ###########lets change the directory and check the service account 
  root@accessor:/# cd /run/secrets/kubernetes.io/serviceaccount
root@accessor:/run/secrets/kubernetes.io/serviceaccount# ls
ca.crt  namespace  token
root@accessor:/run/secrets/kubernetes.io/serviceaccount# cat namespace
defaultroot@accessor:/run/secrets/kubernetes.io/serviceaccount# cat token 
eyJhbGciOiJSUzI1NiIsImtpZCI6ImxIX1ppVkRsX1JueGx3N19xUzlERTl1ZEFsX3ZRcnNQYnJfc1d6bTBQU0EifQ.eyJhdWQiOlsiaHR0cHM6Ly9rdWJlcm5ldGVzLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWwiXSwiZXhwIjoxNzc1MTE1MjY0LCJpYXQiOjE3NDM1NzkyNjQsImlzcyI6Imh0dHBzOi8va3ViZXJuZXRlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsIiwianRpIjoiYmY3MjExMzgtZjQ5ZS00ZDdkLWI3N2MtNzE3YjlhZDI5NzQyIiwia3ViZXJuZXRlcy5pbyI6eyJuYW1lc3BhY2UiOiJkZWZhdWx0Iiwibm9kZSI6eyJuYW1lIjoiazhzLXdvcmtlci1ub2RlLTEiLCJ1aWQiOiIxZjU3YzEyMC1iYjFlLTQzMmUtYjc0YS0zNWI5MDMyYzdlOWUifSwicG9kIjp7Im5hbWUiOiJhY2Nlc3NvciIsInVpZCI6IjUzOTg3Nzc4LWQwM2UtNDQ2Ni04ZDgyLTk1ZGUxNmQ5MmEwMiJ9LCJzZXJ2aWNlYWNjb3VudCI6eyJuYW1lIjoiYWNjZXNzb3IiLCJ1aWQiOiJmODg2OWE1NS0wYmZiLTQzZGYtYTRmZi0xYzU1YzM0YjBmMWUifSwid2FybmFmdGVyIjoxNzQzNTgyODcxfSwibmJmIjoxNzQzNTc5MjY0LCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6ZGVmYXVsdDphY2Nlc3NvciJ9.HHdqQA45MHfhhkbodbnloIGc4MkmSlJdxr1dLHSwyriNwBTyl9_LN_RcCMiOwwFVBkQCz_tadYSrK1cQOGx3RlIRTW0Nd8J7AUB79bM6zPaiogBc2fyl8eQduhlqF3aZURxZGoXpr2JoU1zkYu2Ks_SvDwELo9csYuJtwqODoX5bVyGJ586N6O_7zwvj3T18OpAKMMopccq33_NFkBXuCSrFkEhP2Q344EgOrxeF-QMJVqhqwz1xwg1CWqqS-KT5U0gzaiYviP4GNkTgs_8rzbcpAqg62d1r0Kaz7L2OPCTBYstbJXhWZPsrj44LvOnNLiinCKwRkUfLHJDaNjt8UAroot@accessor:/run/secrets/kubernetes.io/serviceaccount# 
  ##how can we check the same lets go to jew inspector and past the token in jwt.io 
    },
  "nbf": 1743579264,
  "sub": "system:serviceaccount:default:accessor"
}
#same
  #sometime we need to check the service account mappen to your k8s cluster from isnide the pod only
  io/serviceaccount# env | grep KUBER
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_SERVICE_PORT=443
KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
KUBERNETES_SERVICE_HOST=10.96.0.1
KUBERNETES_PORT=tcp://10.96.0.1:443
KUBERNETES_PORT_443_TCP_PORT=443
  #the belwo command show certificate is not valid 
root@accessor:/run/secrets/kubernetes.io/serviceaccount# curl https://10.96.0.1
curl: (60) SSL certificate problem: unable to get local issuer certificate
More details here: https://curl.se/docs/sslcerts.html

curl failed to verify the legitimacy of the server and therefore could not
establish a secure connection to it. To learn more about this situation and
  root@accessor:/run/secrets/kubernetes.io/serviceaccount# curl https://10.96.0.1 -k
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "forbidden: User \"system:anonymous\" cannot get path \"/\"",
  "reason": "Forbidden",
  "details": {},
  "code": 403
    ###########
    we idenitfy system anonumus
    ########lets try to change it we will pass and new header called as authorization
    root@accessor:/run/secrets/kubernetes.io/serviceaccount# curl https://10.96.0.1 -k -H "Authorization: Bearer $(cat token)"
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "forbidden: User \"system:serviceaccount:default:accessor\" cannot get path \"/\"",
  "reason": "Forbidden",
  "details": {},
  "code": 403
}root@accessor:/run/secret
    
how to fix it, please visit the web page mentioned above.
